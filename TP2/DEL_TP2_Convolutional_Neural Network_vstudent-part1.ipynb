{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "110b3ea8",
   "metadata": {},
   "source": [
    "<font  style=\"font-size: 3rem; color: darkviolet\"> Convolutional Neural Networks in TensorFlow - *part 1* </font>\n",
    "\n",
    "DEL - 2023/24 - TP2 (1h30)\n",
    "\n",
    "*This assignement is inspired by the Deep Learning course on Coursera by Andrew Ng, Stanford University, for which we are thankful.*\n",
    "\n",
    "In this assignment, you will gain practical experience in constructing and training Convolutional Neural Networks (ConvNets) using the TensorFlow Keras Sequential API. This API offers an intuitive and straightforward approach to constructing and training ConvNets within the TensorFlow framework. It is suited for tasks that involve a sequential flow, where each layer has precisely one input tensor and one output tensor.\n",
    "\n",
    "You can access the documentation for the Sequential API at the following link: https://www.tensorflow.org/guide/keras/sequential_model\n",
    "\n",
    "You will develop a binary classifier utilizing the Sequential API to determine the emotional state of an individual as either positive or negative. \n",
    "\n",
    "### Table of Contents\n",
    "- [1 - The Happy House Dataset](#1)\n",
    "- [2 - Creating the Sequential Model](#2)\n",
    "- [3 - Training and Evaluating the Model](#3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7de70dde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T11:17:45.223700900Z",
     "start_time": "2023-11-06T11:17:03.396777800Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl\n",
    "\n",
    "from data.test_utils import summary, comparator\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc9235a",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## <font color='darkviolet'> 1 - The Happy House Dataset\n",
    "\n",
    "The Happy House dataset is a collection of facial images, and your task is to develop a ConvNet capable of effectively determining whether the individuals in these images are smiling or not. This task holds significance, as only those with a genuine smile will gain access to the Happy House."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2de8fd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T11:17:45.239211400Z",
     "start_time": "2023-11-06T11:17:45.167621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['list_classes', 'train_set_x', 'train_set_y']\n"
     ]
    }
   ],
   "source": [
    "# Run the following lines to load the training and test datasets\n",
    "train_dataset = h5py.File('data/train_happy.h5', \"r\")\n",
    "test_dataset = h5py.File('data/test_happy.h5', \"r\")\n",
    "\n",
    "# Retrieve the keys within a HDF5 file\n",
    "dataset_keys = list(train_dataset.keys())\n",
    "print(dataset_keys[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a5093c",
   "metadata": {},
   "source": [
    "<a name='ex-1'></a>\n",
    "### <font color='blue'> Exercise 1 - load_happy_dataset\n",
    "\n",
    "<font color='blue'>**1.1** <font color='black'> Implement a function, `load_happy_dataset`, that loads both the training and test datasets from the provided external files: extract the features and labels for both sets and return them as NumPy arrays. Ensure that you reshape the labels to match the expected shape (m, 1), where 'm' is the number of examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd1efa59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T11:17:45.241713100Z",
     "start_time": "2023-11-06T11:17:45.191348500Z"
    }
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (3289724065.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn [3], line 3\u001B[1;36m\u001B[0m\n\u001B[1;33m    #TODO\u001B[0m\n\u001B[1;37m         ^\u001B[0m\n\u001B[1;31mIndentationError\u001B[0m\u001B[1;31m:\u001B[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def load_happy_dataset():\n",
    "    train_dataset = h5py.File('data/train_happy.h5', \"r\")\n",
    "    test_dataset = h5py.File('data/test_happy.h5', \"r\")\n",
    "    train_features = train_dataset  \n",
    "    return \n",
    "    #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd0aaeb",
   "metadata": {},
   "source": [
    "<font color='blue'>**1.2** <font color='black'> Normalise the input images by scaling pixel values to the range [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3410bbf",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-06T11:17:45.207001300Z"
    }
   },
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088eef59",
   "metadata": {},
   "source": [
    "<font color='blue'>**1.3** <font color='black'> Provide a description of your dataset, including its size, dimensions, labels, and the distribution of labels. Display a few images to visualize the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eafaf4e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-06T11:17:45.207001300Z"
    }
   },
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e46a985",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## <font color='darkviolet'> 2 - Creating the Sequential Model\n",
    "\n",
    "Constructing a Sequential model in Keras entails assembling a sequence of layers within the Sequential constructor. These layers collectively define the architecture of your ConvNet, and the order in which you arrange them determines the sequence of transformations applied to the input data.\n",
    "\n",
    "It's important to note that in Keras, you must specify the input shape for your model. This is because the shape of the layer weights is determined by the shape of the inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8837b35",
   "metadata": {},
   "source": [
    "<a name='ex-2'></a>\n",
    "### <font color='blue'> Exercise 2 - happyModel\n",
    "\n",
    "<font color='blue'>**2.1** <font color='black'>Implement the `happyModel` function to create a specific ConvNet model with the following layers: `ZeroPadding2D -> Conv2D -> BatchNormalization -> ReLU -> MaxPooling2D -> Flatten -> Dense`.\n",
    "    \n",
    "You can use the documentation for reference: [tf.keras.layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers).\n",
    "\n",
    "Here are the configuration details for each layer:\n",
    "    \n",
    " - ZeroPadding2D: apply padding of 3 pixels to the input shape.\n",
    " - Conv2D: use 32 filters of size 7x7 with a stride of 1.\n",
    " - BatchNormalization: perform batch normalization along the depth axis (i.e., the channels or feature maps).\n",
    " - ReLU: apply Rectified Linear Unit activation function.\n",
    " - MaxPool2D: use default parameters for max pooling.\n",
    " - Flatten: flatten the previous output.\n",
    " - Fully-connected (Dense) layer: add a fully connected layer with 1 neuron and a sigmoid activation.\n",
    "\n",
    "You can introduce these layers into a Sequential model using the `.add()` method. \n",
    "    \n",
    "Note: Batch Normalization (BN) normalizes the inputs to a layer by subtracting the mean and dividing by the standard deviation of the mini-batch. This centers the data around zero and scales it to have a standard deviation of one. The mean and variance for each channel are computed during training and remain constant during inference. After normalization, BN introduces learnable parameters, gamma and beta, for each channel in the layer. Gamma values allow the network to increase or decrease the importance of each channel's features, while the beta parameter enables fine adjustments to the normalized values for a better fit to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1616c41",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-06T11:17:45.222053800Z"
    }
   },
   "outputs": [],
   "source": [
    "def happyModel():\n",
    "    \n",
    "    #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaaadbe",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-06T11:17:45.223700900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test the model implementation\n",
    "happy_model = happyModel()\n",
    "# Print a summary for each layer\n",
    "for layer in summary(happy_model):\n",
    "    print(layer)\n",
    "# The expected layer configurations\n",
    "output = [['ZeroPadding2D', (None, 70, 70, 3), 0, ((3, 3), (3, 3))],\n",
    "            ['Conv2D', (None, 64, 64, 32), 4736, 'valid', 'linear', 'GlorotUniform'],\n",
    "            ['BatchNormalization', (None, 64, 64, 32), 128],\n",
    "            ['ReLU', (None, 64, 64, 32), 0],\n",
    "            ['MaxPooling2D', (None, 32, 32, 32), 0, (2, 2), (2, 2), 'valid'],\n",
    "            ['Flatten', (None, 32768), 0],\n",
    "            ['Dense', (None, 1), 32769, 'sigmoid']]\n",
    "comparator(summary(happy_model), output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79ec626",
   "metadata": {},
   "source": [
    "<font color='blue'>**2.2** <font color='black'> After designing the deep learning model, the next step is to compile it for training. In the context of TensorFlow and other deep learning frameworks, compiling a model involves configuring various settings that dictate how the training process will proceed. Set the following configurations:\n",
    "\n",
    "- Optimizer: Select the \"Adam\" optimizer with a learning rate of 0.0001.\n",
    "- Loss Function: Specify the \"binary_crossentropy\" loss function, ideal for binary classification tasks like distinguishing between smiling and non-smiling faces.\n",
    "- Metrics: Monitor the \"accuracy\" metric during the training process to assess model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4875e20e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-06T11:17:45.223700900Z"
    }
   },
   "outputs": [],
   "source": [
    "happy_model.compile(#TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c164ebc",
   "metadata": {},
   "source": [
    "<font color='blue'> **Q2.1** Execute the following line: `happy_model.summary()`. What is the distinction between trainable and non-trainable parameters? Can you identify the source of the 64 non-trainable parameters?\n",
    "    \n",
    "<font color='blue'> **Q2.2** How are the total parameters reported per layer calculated? Make the computations and verify your results with the `happy_model.summary()` ouput. \n",
    "    \n",
    "<font color='blue'> **Q2.3** You might have noticed that the first output dimension of a layer is labeled as \"None.\" Can you provide an explanation for this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4d177b",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## <font color='darkviolet'> 3 - Training and Evaluating the Model\n",
    "\n",
    "<font color='blue'>**3.1** <font color='black'> After creating and compiling your model, the next step is to initiate the training process. This is accomplished by calling `.fit()`. This method leverages the underlying TensorFlow framework to automate various aspects of the training process, including backpropagation.\n",
    "\n",
    "The training process may include 20 epochs, a batch size of 32, and a validation split of 80% for training and 20% for validation to monitor the model's performance.\n",
    "\n",
    "You can use the **`ModelCheckpoint`** callback in conjunction with `.fit()` to specify criteria for saving the best model automatically. You can find more details about this callback in the Keras documentation https://keras.io/api/callbacks/model_checkpoint/. Additionally, you can use **`EarlyStopping`** in combination with `ModelCheckpoint`. It helps prevent overfitting by monitoring a specific metric, such as validation accuracy, and stopping training when this metric no longer improves for a certain number of epoch. More information about this callback can be found in the Keras documentation https://keras.io/api/callbacks/early_stopping/.\n",
    "    \n",
    "Note: The .fit() method in Keras returns a History object. This object contains information about the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38103827",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-06T11:17:45.223700900Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57b4517",
   "metadata": {},
   "source": [
    "<font color='blue'> **Q3.1** Observe the training history, including the changes in loss and accuracy over each epoch, for the training and validation dataset. Describe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c91d46b",
   "metadata": {},
   "source": [
    "<font color='blue'>**3.2** <font color='black'>After training your model using `.fit()`, you can evaluate its performance on your test set by calling `.evaluate()`. This function returns the value of the loss function and any performance metrics you specified during compilation. The evaluation provides insights into **how well your model generalizes to unseen data and helps you assess its overall performance**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf0327a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-06T11:17:45.223700900Z"
    }
   },
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daab1d66",
   "metadata": {},
   "source": [
    "<font color='blue'> **Q3.2** How does the performance on the test dataset compare to the training performance you observed during the training process?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
